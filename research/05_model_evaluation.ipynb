{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc9dc87b-042b-4d40-beff-ebff65176949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b105f16-5b6c-42ad-a28d-e88cb169081f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tiva/PycharmProjects/HeadlineGenerator/notebook'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b78ba0f7-3f2a-475e-9af0-4df6c32e0d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65a39e84-84bf-46c2-99a5-c757d1df33a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tiva/PycharmProjects/HeadlineGenerator'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cff12a07-8a07-4fa0-9bca-0e16c581bd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5cf84cd-8e1d-4191-84ee-5fc568a24f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class ModelEvaluationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    model_path: Path\n",
    "    tokenizer_path: Path\n",
    "    metrics_file: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe6fbc60-7e64-44cd-acee-3e8321d88d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from headlineGenerator.constants import *\n",
    "from headlineGenerator.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a4ddb4e-29d3-4429-ad6b-e687e2ff151a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath=CONFIG_FILEPATH, params_filepath=PARAMS_FILEPATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_evaluation_config(self) -> ModelEvaluationConfig:\n",
    "        config = self.config.model_evaluation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_evaluation_config = ModelEvaluationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "            model_path=config.model_path,\n",
    "            tokenizer_path=config.tokenizer_path,\n",
    "            metrics_file=config.metrics_file\n",
    "        )\n",
    "\n",
    "        return model_evaluation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c136e1e6-0632-4f3b-b7f3-032e5e945cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-20 21:11:32,669 || PyTorch version 2.2.0+cpu available.]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datasets import load_from_disk, load_metric, load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "847dd8ec-3f0d-4643-af94-93bca63a53b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluation:\n",
    "    def __init__(self, config: ModelEvaluationConfig):\n",
    "        self.config = config\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    def generate_batches(self, list_of_elements, batch_size):\n",
    "        for i in range(0, len(list_of_elements), batch_size):\n",
    "            yield list_of_elements[i : i+batch_size]\n",
    "\n",
    "    def calculate_metric(self, dataset, metric, model, tokenizer, batch_size, column_story, column_headline):\n",
    "        story_batches = list(self.generate_batches(dataset[column_story], batch_size))\n",
    "        target_batches = list(self.generate_batches(dataset[column_headline], batch_size))\n",
    "\n",
    "        for story_batch, target_batch in tqdm(zip(story_batches, target_batches), total=len(story_batches)):\n",
    "            inputs = tokenizer(story_batch, max_length=1024, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "            headlines = model.generate(\n",
    "                input_ids=inputs[\"input_ids\"].to(self.device),\n",
    "                attention_mask=inputs[\"attention_mask\"].to(self.device),\n",
    "                max_length=30,\n",
    "                length_penalty=0.8,\n",
    "                num_beams=8\n",
    "            )\n",
    "            '''`length_penalty` ensures that the model does not generate sequences that are ...'''\n",
    "\n",
    "            decoded_headlines = [tokenizer.decode(h, skip_special_tokens=True, clean_up_tokenization_spaces=True) for h in headlines]\n",
    "            decoded_headlines = [h.replace(\"\", \" \") for h in decoded_headlines]\n",
    "\n",
    "            metric.add_batch(predictions=[decoded_headlines], references=[target_batches])\n",
    "\n",
    "        score = metric.compute()\n",
    "\n",
    "        return score\n",
    "\n",
    "    def evaluate(self):\n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.config.tokenizer_path)\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(self.config.model_path).to(self.device)\n",
    "        news_dataset = load_from_disk(self.config.data_path)\n",
    "        \n",
    "        rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "        rouge_metric = load_metric(\"rouge\")\n",
    "        \n",
    "        score = self.calculate_metric(news_dataset[\"test\"], rouge_metric, model, tokenizer, 2, \"full_story\", \"headline\")\n",
    "        \n",
    "        rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "        df = pd.DataFrame(rouge_dict, index=[\"t5-small\"])\n",
    "        df.to_csv(self.config.metrics_file, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b58d97b-afb0-4ddb-9f1c-c692aececf1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-20 21:11:51,594 || yaml file : config.yaml loaded successfully]\n",
      "[2024-03-20 21:11:51,659 || yaml file : params.yaml loaded successfully]\n",
      "[2024-03-20 21:11:51,672 || created directory at artifacts]\n",
      "[2024-03-20 21:11:51,673 || created directory at artifacts/model_evaluation]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3466/3169421666.py:40: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  rouge_metric = load_metric(\"rouge\")\n",
      "/home/tiva/PycharmProjects/HeadlineGenerator/venv/lib/python3.8/site-packages/datasets/load.py:756: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/rouge/rouge.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Using the latest cached version of the module from /home/tiva/.cache/huggingface/modules/datasets_modules/metrics/rouge/457c405cab0bd19db749b46bf15a1a3cff4d54f50e7ab868c293e5ece288425e (last modified on Mon Mar 18 05:19:34 2024) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-20 21:12:09,705 || Using the latest cached version of the module from /home/tiva/.cache/huggingface/modules/datasets_modules/metrics/rouge/457c405cab0bd19db749b46bf15a1a3cff4d54f50e7ab868c293e5ece288425e (last modified on Mon Mar 18 05:19:34 2024) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [15:09<00:00, 13.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-20 21:27:20,096 || Using default tokenizer.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_evaluation_config = config.get_model_evaluation_config()\n",
    "    model_evaluation = ModelEvaluation(config=model_evaluation_config)\n",
    "    model_evaluation.evaluate()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b753300-474a-49c8-b9b1-82751e91b98b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3630c710-b04a-41c4-976f-858a97d0adbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "028323d8-d560-4a9a-b30d-b0e407d96f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-20 05:49:14,638 || yaml file : config.yaml loaded successfully]\n",
      "[2024-03-20 05:49:14,644 || yaml file : params.yaml loaded successfully]\n",
      "[2024-03-20 05:49:14,645 || created directory at artifacts]\n",
      "[2024-03-20 05:49:14,647 || created directory at artifacts/model_evaluation]\n"
     ]
    }
   ],
   "source": [
    "config = ConfigurationManager().get_model_evaluation_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4beab5fd-0d8d-4e37-92c1-b81c7d5e3c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(list_of_elements, batch_size):\n",
    "    for i in range(0, len(list_of_elements), batch_size):\n",
    "        yield list_of_elements[i : i+batch_size]\n",
    "\n",
    "news_dataset = load_from_disk(config.data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b43faada-19a5-4b18-8b0d-c2d35e4d93c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = news_dataset[\"test\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15d707b5-9be6-4e2b-80a9-2b885313625f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stories = list(generate_batches(test_data[\"full_story\"], 2))\n",
    "headlines = list(generate_batches(test_data[\"headline\"], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d41fe4b-a641-424d-a028-b44d845b2ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['nigeria not in a debt crisis â€“ finance minister',\n",
       "  'argentina win first world cup after 36 years'],\n",
       " ['reece james is chelseaâ€™s new captain, makes three big promises',\n",
       "  'nigerian passport holders have access to just 2.1% of worldâ€™s gdp â€“ forbes'],\n",
       " ['nigeria central bank to mandate banks to raise capital base',\n",
       "  'oscars 2023: chris rock turns down offer to host'],\n",
       " ['peseiro says main focus is to win afcon for nigeria',\n",
       "  'chukwueze delighted with laliga award, vows to do more for villarreal'],\n",
       " ['afcon qualifier: super eagles camp bubbles as osimhen, awoniyi, others arrive uyo',\n",
       "  'super eagles off to abidjan for afcon 2023']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6357645c-5049-44e8-9d18-7ad07ef911ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiva/PycharmProjects/HeadlineGenerator/venv/lib/python3.8/site-packages/datasets/load.py:756: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/rouge/rouge.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Using the latest cached version of the module from /home/tiva/.cache/huggingface/modules/datasets_modules/metrics/rouge/457c405cab0bd19db749b46bf15a1a3cff4d54f50e7ab868c293e5ece288425e (last modified on Mon Mar 18 05:19:34 2024) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-20 05:50:51,266 || Using the latest cached version of the module from /home/tiva/.cache/huggingface/modules/datasets_modules/metrics/rouge/457c405cab0bd19db749b46bf15a1a3cff4d54f50e7ab868c293e5ece288425e (last modified on Mon Mar 18 05:19:34 2024) since it couldn't be found locally at rouge, or remotely on the Hugging Face Hub.]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(config.tokenizer_path)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(config.model_path)\n",
    "        \n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "rouge_metric = load_metric(\"rouge\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf99e34e-58fa-4553-a7ea-e7bfff7c2a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28437bcc-78ec-40ed-9908-bb2608bc4d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for story_batch, target_batch in tqdm(zip(stories, headlines), total=len(story_batches)):\n",
    "    inputs = tokenizer(story_batch, max_length=1024, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "    headlines = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"].to(self.device),\n",
    "        attention_mask=inputs[\"attention_mask\"].to(self.device),\n",
    "        max_length=30,\n",
    "        length_penalty=0.8,\n",
    "        num_beams=8\n",
    "    )\n",
    "    '''`length_penalty` ensures that the model does not generate sequences that are ...'''\n",
    "    \n",
    "    decoded_headlines = [tokenizer.decode(h, skip_special_tokens=True, clean_up_tokenization_spaces=True) for h in headlines]\n",
    "    decoded_headlines = [h.replace(\"\", \" \") for h in decoded_headlines]\n",
    "    \n",
    "    metric.add_batch(predictions=decoded_headlines, references=target_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c6c6d40-0bf9-4dee-8d94-e186a29e7c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = stories[0]\n",
    "h = headlines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ba8848e-ed9e-4ccb-a046-77e89765e61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(s, max_length=1024, truncation=True, padding=\"max_length\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43068c83-ee9c-4740-87f6-343833d82561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1024])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d9ae5b1-f68d-418c-a2cf-e37ca4a0f829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1024])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[\"attention_mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8437c6b-a2ce-4bbd-84f2-abb1984b0f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_gen = model.generate(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"], max_length=30, length_penalty=0.8, num_beams=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ffc119a2-1586-4529-9a43-fa955f567346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 30])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_gen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16f40593-dbe5-43a1-93d0-48d65b04cd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_dec = [tokenizer.decode(h, skip_special_tokens=True, clean_up_tokenization_spaces=True) for h in h_gen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e4b1e1ed-8e1f-4350-933a-f72b50d1f058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[', zainab ahmed, said nigeriaâ€™s debt profile is within reasonable limit. nigeria',\n",
       " 'argentina beat france 4-2 on a penalty shoot-out to win the world cup for the third time in qa']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c9e9b948-d256-4ce7-9a22-067b36a8d0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_dec = [h.strip() for h in h_dec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4dc8e38f-f3f3-47e1-944f-5fc1a02cb947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[', zainab ahmed, said nigeriaâ€™s debt profile is within reasonable limit. nigeria',\n",
       " 'argentina beat france 4-2 on a penalty shoot-out to win the world cup for the third time in qa']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "610fa81c-f5b2-4494-9032-9cdff9d823fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nigeria not in a debt crisis â€“ finance minister',\n",
       " 'argentina win first world cup after 36 years']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "33f25c8a-458f-4fa8-afa4-1cda689380eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_metric.add_batch(predictions=h_dec, references=h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bfb2b6d0-6ac2-4104-980c-50c88dc30b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-20 06:08:06,865 || Using default tokenizer.]\n"
     ]
    }
   ],
   "source": [
    "score = rouge_metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e6d26163-d1f5-41bc-b993-a8d2deb28e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_dict = dict((rn, score[rn]) for rn in rouge_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bd63ac5b-5c58-48a9-93bc-3c1546802999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': AggregateScore(low=Score(precision=0.16666666666666666, recall=0.25, fmeasure=0.2), mid=Score(precision=0.17857142857142855, recall=0.375, fmeasure=0.23793103448275862), high=Score(precision=0.19047619047619047, recall=0.5, fmeasure=0.27586206896551724)),\n",
       " 'rouge2': AggregateScore(low=Score(precision=0.0, recall=0.0, fmeasure=0.0), mid=Score(precision=0.025, recall=0.07142857142857142, fmeasure=0.03703703703703704), high=Score(precision=0.05, recall=0.14285714285714285, fmeasure=0.07407407407407408)),\n",
       " 'rougeL': AggregateScore(low=Score(precision=0.16666666666666666, recall=0.25, fmeasure=0.2), mid=Score(precision=0.17857142857142855, recall=0.375, fmeasure=0.23793103448275862), high=Score(precision=0.19047619047619047, recall=0.5, fmeasure=0.27586206896551724)),\n",
       " 'rougeLsum': AggregateScore(low=Score(precision=0.16666666666666666, recall=0.25, fmeasure=0.2), mid=Score(precision=0.17857142857142855, recall=0.375, fmeasure=0.23793103448275862), high=Score(precision=0.19047619047619047, recall=0.5, fmeasure=0.27586206896551724))}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f2c6733e-249e-4a21-838a-219c44406bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.23793103448275862,\n",
       " 'rouge2': 0.03703703703703704,\n",
       " 'rougeL': 0.23793103448275862,\n",
       " 'rougeLsum': 0.23793103448275862}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b739a3-8316-49b5-8edf-a7274cbc407f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
